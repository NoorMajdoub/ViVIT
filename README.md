
# ViViT Exploration

This repository is my personal playground for exploring **ViViT (Video Vision Transformer)**.
Right now, the focus is just on understanding and playing with the model â€” nothing fancy yet ðŸ˜Ž.

---

## About

ViViT is a transformer-based model for **video understanding**, capturing both **spatial** (within-frame) and **temporal** (across-frame) patterns.
In this repo, Iâ€™m using the **ViT / ViViT implementation** from [lucidrains/vit-pytorch](https://github.com/lucidrains/vit-pytorch).

---

## Repository Contents

* `README.md` â€” this file
* `notes/` â€” my personal notes about ViViT, ideas, and experiments
* `code/` later 

---

## Goals (so far)

* Understand how ViViT processes videos
* Learn how to use pretrained ViViT models for **video classification or action recognition**
* Keep notes on findings and next steps

---

## Status

ðŸš§ Work in progress â€” mostly notes and experimental code at this point.
Expect more examples, scripts, and experiments soon.

---

### References

* [lucidrains/vit-pytorch](https://github.com/lucidrains/vit-pytorch)
* Original ViViT paper: [Google Research ViViT](https://arxiv.org/abs/2103.15691)



Do you want me to do that?

